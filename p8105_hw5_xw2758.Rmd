---
title: "p8105_hw5_xw2758"
author: "Xinyi Wang"
date: "11/18/2020"
output: github_document
---

```{r setup}
library(tidyverse)
library(rvest)

knitr::opts_chunk$set(
	echo = TRUE,
	fig.asp = 0.6,
	fig.width = 6,
	out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

```{r}
homicide_df = 
  read_csv("homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL")
```


Let's look at this a bit

```{r}
aggregate_df = 
  homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )
```

Can I do a prop test for a single city?

```{r}
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved), 
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>% 
  broom::tidy()
```

Try to iterate ........

```{r}
results_df = 
  aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```



```{r}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```


# Problem 2

**1.create a dataframe containing all file names**

```{r}
filename_df = tibble( path = list.files("data/"))
```

**2.Iterate over file names and read in data for each subject**

```{r}
 arm_df = filename_df %>% 
 mutate(
 path = str_c("data/", path),
 map_df(.x = path, read.csv)
 ) 
arm_df
```

**3.Tidy the result**

```{r}
arm_df_tidy = 
  arm_df %>%
  mutate(
    path = str_remove_all(path,".csv"),
    path = str_remove_all(path, "data/")
  ) %>%
  separate(path, into = c("arm","id"), sep = 3) %>%
  mutate(
    id = str_remove_all(id, "_"),
    arm = str_replace(arm,"con","control"),
    arm = str_replace(arm,"exp","experiment")
  ) %>% 
 pivot_longer(
  week_1:week_8,
  names_prefix = "week_",
  names_to = "week",
  values_to = "value"
 )
arm_df_tidy
```

**4.Make a spaghetti plot**

```{r}
arm_df_tidy %>% unite("arm_id",c(arm,id), sep = "_", remove = F) %>%
  ggplot(aes(x = week,y = value)) +
  geom_point(aes(color = arm,group = id)) +
  geom_path(aes(colour = arm,group = arm_id),alpha = .5)

```

Comment: At first, two group are similar and experimental group has larger standard deviation. With time by, control group is stable, while the value of experiment group increases.


# Problem 3

**Set mu = 0. Generate 5000 datasets from the model,Repeat the above for mu = {1,2,3,4,5,6}**

```{r}
set.seed(33)
sim_t_test = function(samp_size = 30, mu = 0, sigma = 5) {
 sim_data = tibble(
  x = rnorm(samp_size, mean = mu, sd = sigma),
  )
  sim_data  = t.test(sim_data, conf.level = 0.95) %>% 
  broom::tidy() %>% 
  select(estimate, p.value)
}

sim_repeat = 
  tibble(mu_true = c(0,1,2,3,4,5,6)) %>% 
  mutate(
    output_lists = map(.x = mu_true, ~rerun(5000, sim_t_test(mu = .x))),
    estimate_dfs = map(output_lists, bind_rows)) %>% 
  select(-output_lists) %>% 
  unnest(estimate_dfs)
```

**Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of mu on the x axis**

```{r}
sim_repeat %>% 
    group_by(mu_true) %>% 
    filter(p.value<0.05) %>% 
    summarize(
      count = n(),
      proportion = count/5000
      ) %>% 
ggplot(aes(x = mu_true, y = proportion, fill = mu_true)) +
  geom_histogram(stat="identity", width = .5) +
  labs(
    x = "true value of mu",
    y = "proportion",
    title = "plot of power in different Î¼"
    )
```

Comment: when mu is low, the proportion of times the null was rejected is low. However, the power of the test becomes stronger when mu is larger. When mu = 6, the proportion is almost 1.Since the null hypothesis is mu = 0, it make senses that when mu_true gets bigger, the probability of "mu =0" is getting lower. 

**Make a plot showing the average estimate of mu on the y axis and the true value of mu on the x axis. Make a second plot (or overlay on the first) the average estimate of mu  only in samples for which the null was rejected on the y axis and the true value of mu on the x axis.**

```{r}
sim_repeat %>% 
  group_by(mu_true) %>% 
  summarize(mean_estimate_mu = mean(estimate)) %>% 
ggplot(aes(x = mu_true, y = mean_estimate_mu, fill = mu_true)) +
  geom_histogram(stat="identity", width = .5) +
  labs(
    x = "true value of mu",
    y = "mean of etimate mu",
    title = "plot of true value and estimate mean"
    )
```

```{r}
  sim_repeat %>% 
    group_by(mu_true) %>% 
    filter(p.value<0.05) %>% 
    summarize(mean_estimate_mu = mean(estimate)) %>% 
   ggplot(aes(x = mu_true, y = mean_estimate_mu, fill = mu_true)) +
  geom_histogram(stat="identity", width = .5) +
  labs(
    x = "true value of mu",
    y = "mean of etimate mu(only in samples for which the null was rejected)",
    title = "plot of ture value and null-reject estimate mean"
    )
```

We can find that when mu is small, estimate mu of samples for which the null was rejected is different with true mu. When mu is large, two estimate are similar.

That is because when mu is small, it fails to reject null hypothesis and lots of them are kept and estimate around 1. When the mu is large, the power of test is stronger and lots of them are rejected, so the estimate and true are close.

